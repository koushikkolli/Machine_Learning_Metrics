{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common evaluation metrics used for Classification\n",
    "* Accuracy\n",
    "* Precision (P)\n",
    "* Recall (R)\n",
    "* F1 Score (F1)\n",
    "* Area under the curve (AUC)\n",
    "* Log loss\n",
    "* Precision at k (P@k)\n",
    "* Average Precision at k (AP@k)\n",
    "* Mean Average precision at k(MAP@k)\n",
    "\n",
    "# Most common evaluation metrics used for Regression\n",
    "* Mean Absolute Error (MAP)\n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Root Mean Squared Logarithimic Error (RMSLE)\n",
    "* Mean Percentage Error (MPE)\n",
    "* Mean Absolute Percentage Error (MAPE)\n",
    "* R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification  Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have equal number of positive and negative samples in a binary classification problem, we can use Accuracy, Precision Recall and F1 Score\n",
    "\n",
    "__Accuracy__: Accuracy defines how accurate is the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom accuracy function: 0.75\n",
      "Scikit-learn accuracy function: 0.75\n"
     ]
    }
   ],
   "source": [
    "# custom function for accuracy\n",
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: accuracy_score\n",
    "    \"\"\"\n",
    "    # initialize the counter to zero\n",
    "    correct_counter = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct_counter += 1\n",
    "    \n",
    "    return correct_counter / len(y_true)\n",
    "\n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 1]\n",
    "print(\"Custom accuracy function: \" + str(accuracy(l1, l2)))\n",
    "\n",
    "# accuracy using scikit-learn\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Scikit-learn accuracy function: \" + str(metrics.accuracy_score(l1, l2)))    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definitions__\n",
    "\n",
    "__True Positive (TP)__ : If the true value is positive and predicted value is also positive\n",
    "\n",
    "__True Negative (TN)__ : If the true value is negative and predicted value is also negative\n",
    "\n",
    "__Flase Positive (FP)__ : If the true value is negative and predicted value is positive\n",
    "\n",
    "__False Negative (FN)__ : If the true value is positive and predicted value is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 2\n",
      "True Negatives: 3\n",
      "False Positives: 1\n",
      "False Negatives: 2\n"
     ]
    }
   ],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Positives\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: number of True Positives\n",
    "    \"\"\"\n",
    "    tp_counter = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp_counter += 1\n",
    "    return tp_counter\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Negatives\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: number of True Negatives\n",
    "    \"\"\"\n",
    "    tn_counter = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn_counter += 1\n",
    "    return tn_counter\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Positives\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: number of True Positives\n",
    "    \"\"\"\n",
    "    fp_counter = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp_counter += 1\n",
    "    return fp_counter\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Negatives\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: number of False Negatives\n",
    "    \"\"\"\n",
    "    fn_counter = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn_counter += 1\n",
    "    return fn_counter\n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"True Positives: \" + str(true_positive(l1, l2)))\n",
    "print(\"True Negatives: \" + str(true_negative(l1, l2)))\n",
    "print(\"False Positives: \" + str(false_positive(l1, l2)))\n",
    "print(\"False Negatives: \" + str(false_negative(l1, l2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Precision (P)__: Out of the total predictions that are positive, what fraction of them are actually positive\n",
    "        \n",
    "        Precision = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Precision\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: precision score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true,y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"Precision: \", precision(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recall (R)__: Out of the total true positives, what fraction of them are predicted positive\n",
    "        \n",
    "        Recall = TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.5\n"
     ]
    }
   ],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate recall\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: recall score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true,y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"Recall: \", recall(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__F1 Score__: F1 Score combines the precision and recall to give a single metric. It is a harmonic mean between Precision and recall. In case of skewed targets, we can look at F1 Scores instead of accuracy\n",
    "\n",
    "        F1 = 2PR / (P + R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom F1 Score function:  0.5714285714285715\n",
      "Scikit-learn F1 Score function:  0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate F1 Score\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: F1 score\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return (2 * p * r) / (p + r)\n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"Custom F1 Score function: \", f1_score(l1, l2))\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Scikit-learn F1 Score function: \", metrics.f1_score(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TPR (True Positive Rate)__ or Recall is also known as sensitivity\n",
    "    \n",
    "        TPR = TP / (TP + FN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Rate:  0.5\n"
     ]
    }
   ],
   "source": [
    "def tpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate tpr\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: tpr/recall\n",
    "    \"\"\"\n",
    "    return recall(y_true, y_pred) \n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"Total Positive Rate: \", recall(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__False Positive Rate (FPR)__ is defined as\n",
    "\n",
    "        FPR = FP / (TN + FP)\n",
    "__1 - FPR__ is known as __specificity or True Negative Rate or TNR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate:  0.25\n",
      "True Negative rate:  0.75\n"
     ]
    }
   ],
   "source": [
    "def fpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate fpr\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: fpr\n",
    "    \"\"\"\n",
    "    fp = false_positive(y_true,y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    return fp / (tn + fp)\n",
    "\n",
    "def tnr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate tnr\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: tnr\n",
    "    \"\"\"\n",
    "    return 1 - fpr(y_true, y_pred)\n",
    "\n",
    "\n",
    "l1 = [0, 1, 1, 1, 0, 0, 0, 1]\n",
    "l2 = [0, 1, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "print(\"False positive rate: \", fpr(l1, l2))\n",
    "print(\"True Negative rate: \", tnr(l1, l2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC (Area under the curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:  0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "l1 = [0, 0, 1, 1]\n",
    "l2 = [0.1, 0.4, 0.35, 0.8]\n",
    "\n",
    "print(\"AUC Score: \", metrics.roc_auc_score(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log loss\n",
    "    Log loss = -1.0 * (target * log(prediction) + (1 - target) * log(1 - prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Log loss function:  0.49882711861432294\n",
      "Scikit-learn Log loss fumction 0.49882711861432294\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_loss(y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Function to calculate log loss\n",
    "    :param y_true: list of true target values\n",
    "    :param y_proba: list of predicted probability values\n",
    "    :result: overall log loss\n",
    "    \"\"\"\n",
    "    # define epsilon value which will be used to clip probabilities\n",
    "    epsilon = 1e-15\n",
    "    \n",
    "    loss = []\n",
    "    for yt, yp in zip(y_true, y_proba):\n",
    "        # clipping the probability\n",
    "        yp = np.clip(yp, epsilon, 1 - epsilon)\n",
    "        temp_loss = -1.0 *(\n",
    "            yt * np.log(yp) \n",
    "            + (1 - yt) * np.log(1 - yp)\n",
    "        )\n",
    "        loss.append(temp_loss)\n",
    "    return np.mean(loss)\n",
    "\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "         0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_proba =[0.1, 0.3, 0.2,0.6, 0.8, 0.05,\n",
    "         0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "         0.85, 0.15, 0.99]\n",
    "print(\"Custom Log loss function: \", log_loss(y_true, y_proba))\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Scikit-learn Log loss fumction\",metrics.log_loss(y_true, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi class classification\n",
    "\n",
    "__Macro Averaged Precision__: Calculate precision for all the classes individually and then average them\n",
    "\n",
    "__Micro Averaged Precision__: Calculate class wise true positive and false positive and use that to calculate the overall precision\n",
    "\n",
    "__Weighted Precision__: Same as macro but in this case,it is weighted average depending on the number of items in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Macro Averaged Precision Function:  0.3611111111111111\n",
      "Scikit-learn Macro Averaged Precision Function:  0.3611111111111111\n",
      "====================================================================================\n",
      "Custom Micro Averaged Precision Function:  0.4444444444444444\n",
      "Scikit-learn Micro Averaged Precision Function:  0.4444444444444444\n",
      "====================================================================================\n",
      "Custom Weighted Averaged Precision Function:  0.39814814814814814\n",
      "Scikit-learn Weighted Averaged Precision Function:  0.39814814814814814\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "\n",
    "def macro_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Macro Averaged Precision\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: macro precision score\n",
    "    \"\"\"\n",
    "    # getting the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializing the precision to zero\n",
    "    precision = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        #filtering based on the calss\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        \n",
    "        temp_precision = tp / (tp + fp)\n",
    "        precision += temp_precision\n",
    "    return precision / num_classes\n",
    "\n",
    "def micro_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Micro Averaged Precision\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: micro precision score\n",
    "    \"\"\"\n",
    "    # finding the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializing the true positives and false positives to zero\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # filtering based on the class\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        fp += false_positive(temp_true, temp_pred)\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "def weighted_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Weighted Averaged Precision\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: weighted precision score\n",
    "    \"\"\"\n",
    "    # finding the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # creating the count dictionary\n",
    "    class_counts = Counter(y_true)\n",
    "    \n",
    "    # initializing the precision to zero\n",
    "    precision = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # filtering based on calss\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        # calculating the temporary precision\n",
    "        temp_precision = tp / (tp + fp)\n",
    "        # calculating the weighted precision\n",
    "        weighted_precision = class_counts[class_] * temp_precision\n",
    "        # adding to the overall precision\n",
    "        precision += weighted_precision\n",
    "    \n",
    "    return precision / len(y_true)\n",
    "\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "print(\"Custom Macro Averaged Precision Function: \", macro_precision(y_true, y_pred))\n",
    "print(\"Scikit-learn Macro Averaged Precision Function: \", metrics.precision_score(y_true, y_pred, average=\"macro\"))\n",
    "print(\"====================================================================================\")\n",
    "print(\"Custom Micro Averaged Precision Function: \", micro_precision(y_true, y_pred))\n",
    "print(\"Scikit-learn Micro Averaged Precision Function: \", metrics.precision_score(y_true, y_pred, average=\"micro\"))\n",
    "print(\"====================================================================================\")\n",
    "print(\"Custom Weighted Averaged Precision Function: \", weighted_precision(y_true, y_pred))\n",
    "print(\"Scikit-learn Weighted Averaged Precision Function: \", metrics.precision_score(y_true, y_pred, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Macro Averaged Recall__: Calculate recall for all the classes individually and then average them\n",
    "\n",
    "__Micro Averaged Recall__: Calculate class wise true positive and false negatives and use that to calculate the overall precision\n",
    "\n",
    "__Weighted Recall__: Same as macro but in this case,it is weighted average depending on the number of items in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Macro Averaged Recall Function:  0.4166666666666667\n",
      "Scikit-learn Macro Averaged Recall Function:  0.4166666666666667\n",
      "====================================================================================\n",
      "Custom Micro Averaged Recall Function:  0.4444444444444444\n",
      "Scikit-learn Micro Averaged Recall Function:  0.4444444444444444\n",
      "====================================================================================\n",
      "Custom Weighted Averaged Recall Function:  0.4444444444444444\n",
      "Scikit-learn Weighted Averaged Recall Function:  0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "\n",
    "def macro_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Macro Averaged Recall\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: macro recall score\n",
    "    \"\"\"\n",
    "    # getting the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializing the recall to zero\n",
    "    recall = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        #filtering based on the calss\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fn = false_negative(temp_true, temp_pred)\n",
    "        \n",
    "        temp_recall = tp / (tp + fn)\n",
    "        recall += temp_recall\n",
    "    return recall / num_classes\n",
    "\n",
    "def micro_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Micro Averaged Recall\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: micro recall score\n",
    "    \"\"\"\n",
    "    # finding the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializing the true positives and false positives to zero\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # filtering based on the class\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        fn += false_negative(temp_true, temp_pred)\n",
    "    \n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "def weighted_recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Weighted Averaged Recall\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: weighted recall score\n",
    "    \"\"\"\n",
    "    # finding the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # creating the count dictionary\n",
    "    class_counts = Counter(y_true)\n",
    "    \n",
    "    # initializing the recall to zero\n",
    "    recall = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # filtering based on calss\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fn = false_negative(temp_true, temp_pred)\n",
    "        # calculating the temporary precision\n",
    "        temp_recall = tp / (tp + fn)\n",
    "        # calculating the weighted precision\n",
    "        weighted_recall = class_counts[class_] * temp_recall\n",
    "        # adding to the overall precision\n",
    "        recall += weighted_recall\n",
    "    \n",
    "    return recall / len(y_true)\n",
    "\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "print(\"Custom Macro Averaged Recall Function: \", macro_recall(y_true, y_pred))\n",
    "print(\"Scikit-learn Macro Averaged Recall Function: \", metrics.recall_score(y_true, y_pred, average=\"macro\"))\n",
    "print(\"====================================================================================\")\n",
    "print(\"Custom Micro Averaged Recall Function: \", micro_recall(y_true, y_pred))\n",
    "print(\"Scikit-learn Micro Averaged Recall Function: \", metrics.recall_score(y_true, y_pred, average=\"micro\"))\n",
    "print(\"====================================================================================\")\n",
    "print(\"Custom Weighted Averaged Recall Function: \", weighted_recall(y_true, y_pred))\n",
    "print(\"Scikit-learn Weighted Averaged Recall Function: \", metrics.recall_score(y_true, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Macro Averaged F1 Score__: Calculate F1 Score for all the classes individually and then average them\n",
    "\n",
    "__Micro Averaged F1 Score__: Calculate class wise precision and recall and use that to calculate the overall precision\n",
    "\n",
    "__Weighted F1 Score__: Same as macro but in this case,it is weighted average depending on the number of items in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Macro Averaged F1 Score Function:  0.38095238095238093\n",
      "Scikit-learn Macro Averaged F1 Score Function:  0.38095238095238093\n",
      "====================================================================================\n",
      "Custom Micro Averaged F1 Score Function:  0.4444444444444444\n",
      "Scikit-learn Micro Averaged F1 Score Function:  0.4444444444444444\n",
      "====================================================================================\n",
      "Custom Weighted Averaged F1 Score Function:  0.41269841269841273\n",
      "Scikit-learn Weighted Averaged F1 Score Function:  0.41269841269841273\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Macro Averaged F1 Score\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: macro f1 score\n",
    "    \"\"\"\n",
    "    # getting the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializing the F1 Score to zero\n",
    "    f1 = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        #filtering based on the calss\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        p = precision(temp_true, temp_pred)\n",
    "        r = recall(temp_true, temp_pred)\n",
    "        \n",
    "        if p + r != 0:\n",
    "            temp_f1 = (2 * p * r) / (p + r)\n",
    "        else:\n",
    "            temp_f1 = 0\n",
    "            \n",
    "        f1 += temp_f1\n",
    "        \n",
    "    return f1 / num_classes\n",
    "\n",
    "def micro_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Micro Averaged F1 Score\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: micro f1 score\n",
    "    \"\"\"\n",
    "    # finding the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initializing the true positives, false positives and flase negatives to zero\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # filtering based on the class\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        fn += false_negative(temp_true, temp_pred)\n",
    "        fp += false_negative(temp_true, temp_pred)\n",
    "        \n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    if p + r != 0:\n",
    "        f1 = (2 * p * r) / (p + r)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    return f1 \n",
    "\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Weighted Averaged F1 Score\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: weighted f1 score\n",
    "    \"\"\"\n",
    "    # finding the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # creating the count dictionary\n",
    "    class_counts = Counter(y_true)\n",
    "    \n",
    "    # initializing the recall to zero\n",
    "    f1 = 0\n",
    "    \n",
    "    for class_ in range(num_classes):\n",
    "        # filtering based on calss\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        p = precision(temp_true, temp_pred)\n",
    "        r = recall(temp_true, temp_pred)\n",
    "        if p + r != 0:\n",
    "            temp_f1 = (2 * p * r) / (p + r)\n",
    "        else:\n",
    "            temp_f1 = 0\n",
    "        weighted_f1 = class_counts[class_] * temp_f1\n",
    "        f1 += weighted_f1\n",
    "    \n",
    "    return f1 / len(y_true)\n",
    "\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "print(\"Custom Macro Averaged F1 Score Function: \", macro_f1(y_true, y_pred))\n",
    "print(\"Scikit-learn Macro Averaged F1 Score Function: \", metrics.f1_score(y_true, y_pred, average=\"macro\"))\n",
    "print(\"====================================================================================\")\n",
    "print(\"Custom Micro Averaged F1 Score Function: \", micro_f1(y_true, y_pred))\n",
    "print(\"Scikit-learn Micro Averaged F1 Score Function: \", metrics.f1_score(y_true, y_pred, average=\"micro\"))\n",
    "print(\"====================================================================================\")\n",
    "print(\"Custom Weighted Averaged F1 Score Function: \", weighted_f1(y_true, y_pred))\n",
    "print(\"Scikit-learn Weighted Averaged F1 Score Function: \", metrics.f1_score(y_true, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 48.5, 'Predicted labels')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn import metrics\n",
    "\n",
    "# some targets and predictions\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "# getting confusion matrix from sklearn\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)\n",
    "plt.ylabel(\"Actual labels\", fontsize=20)\n",
    "plt.xlabel(\"Predicted labels\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Metrics for Classification\n",
    "\n",
    "## Quadratic weighted kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic weighted kappa:  0.33333333333333337\n",
      "Accuracy:  0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]\n",
    "\n",
    "print(\"Quadratic weighted kappa: \", metrics.cohen_kappa_score(y_true, y_pred, weights=\"quadratic\"))\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathew's Correlation Coefficient(MCC)\n",
    "* It ranges from -1 to 1. 1 for a perfect prediction, -1 for a imperfect prediction, and 0 is random prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Mathew's Correlation Coefficient\n",
    "    :param y_true: list of true target values\n",
    "    :param y_pred: list of predicted target values\n",
    "    :return: mcc score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    \n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    \n",
    "    denominator = (\n",
    "        (tp + fp) *\n",
    "        (fn + tn) *\n",
    "        (fp + tn) *\n",
    "        (tp + fn)\n",
    "    )\n",
    "    \n",
    "    denominator = denominator ** 0.5\n",
    "    \n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Classification\n",
    "\n",
    "## Suitable and commonly used metrics are\n",
    "* Precision at k (P@k)\n",
    "* Average Precision at k (AP@k)\n",
    "* Mean Average Precision at k (MAP@k)\n",
    "* Log loss\n",
    "\n",
    "__Precision at k (P@k)__: If we have a original list of classes for a given sample and list of predicted classes for the same, precision is defined as the number of hits in the predicted list considering only tpo-k predictions, divided by k\n",
    "\n",
    "__Average Precision at k (AP@k)__: AP@k is calculated using P@k. For example, if we have to calculate AP@3, we have to calculate P@1, P@2, P@3 and divide the sum by 3\n",
    "\n",
    "__Mean Average Precision at k (MAP@k)__: It is just a average of AP@k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            y_true=[1, 2, 3],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1, 2, 3],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@2=0.25\n",
      "            \n",
      "\n",
      "            y_true=[1, 2, 3],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@3=0.38888888888888884\n",
      "            \n",
      "\n",
      "            y_true=[0, 2],\n",
      "            y_pred=[1],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[0, 2],\n",
      "            y_pred=[1],\n",
      "            AP@2=0.0\n",
      "            \n",
      "\n",
      "            y_true=[0, 2],\n",
      "            y_pred=[1],\n",
      "            AP@3=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1],\n",
      "            y_pred=[0, 2, 3],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1],\n",
      "            y_pred=[0, 2, 3],\n",
      "            AP@2=0.0\n",
      "            \n",
      "\n",
      "            y_true=[1],\n",
      "            y_pred=[0, 2, 3],\n",
      "            AP@3=0.0\n",
      "            \n",
      "\n",
      "            y_true=[2, 3],\n",
      "            y_pred=[2, 3, 4, 0],\n",
      "            AP@1=1.0\n",
      "            \n",
      "\n",
      "            y_true=[2, 3],\n",
      "            y_pred=[2, 3, 4, 0],\n",
      "            AP@2=1.0\n",
      "            \n",
      "\n",
      "            y_true=[2, 3],\n",
      "            y_pred=[2, 3, 4, 0],\n",
      "            AP@3=0.8888888888888888\n",
      "            \n",
      "\n",
      "            y_true=[1, 0],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@1=1.0\n",
      "            \n",
      "\n",
      "            y_true=[1, 0],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@2=1.0\n",
      "            \n",
      "\n",
      "            y_true=[1, 0],\n",
      "            y_pred=[0, 1, 2],\n",
      "            AP@3=0.8888888888888888\n",
      "            \n",
      "\n",
      "            y_true=[],\n",
      "            y_pred=[0],\n",
      "            AP@1=0.0\n",
      "            \n",
      "\n",
      "            y_true=[],\n",
      "            y_pred=[0],\n",
      "            AP@2=0.0\n",
      "            \n",
      "\n",
      "            y_true=[],\n",
      "            y_pred=[0],\n",
      "            AP@3=0.0\n",
      "            \n",
      "=========================================================================\n",
      "Mean Average Precision at 1:  0.3333333333333333\n",
      "Mean Average Precision at 2:  0.375\n",
      "Mean Average Precision at 3:  0.3611111111111111\n",
      "Mean Average Precision at 4:  0.34722222222222215\n"
     ]
    }
   ],
   "source": [
    "def pk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Function to calculate Precision at k for a single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :param k: the value for k\n",
    "    :return: precision at given value k\n",
    "    \"\"\"\n",
    "    # we should never have this as k >= 1\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    y_pred = y_pred[:k]\n",
    "    pred_set = set(y_pred)\n",
    "    true_set = set(y_true)\n",
    "    common_values = pred_set.intersection(true_set)\n",
    "    \n",
    "    return len(common_values) / len(y_pred[:k])\n",
    "\n",
    "def apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Function to calculate Average Precision at k for a single sample\n",
    "    :param y_true: list of values, true classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :param k: the value for k\n",
    "    :return: average precision at a given value k\n",
    "    \"\"\"\n",
    "    pk_values = []\n",
    "    for i in range(1, k+1):\n",
    "        pk_values.append(pk(y_true, y_pred, i))\n",
    "    if len(pk_values) == 0:\n",
    "        return 0\n",
    "    return sum(pk_values) / len(pk_values)\n",
    "\n",
    "def mapk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Function to calculate Mean Average Precision at k\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :param k: the value for k\n",
    "    :return: mean average precision at a given value k\n",
    "    \"\"\"\n",
    "    apk_values = []\n",
    "    for i in range(len(y_true)):\n",
    "        apk_values.append(apk(y_true[i], y_pred[i], k))\n",
    "    return sum(apk_values) / len(apk_values)\n",
    "\n",
    "y_true = [\n",
    "    [1, 2, 3],\n",
    "    [0, 2],\n",
    "    [1],\n",
    "    [2, 3],\n",
    "    [1, 0],\n",
    "    []\n",
    "]\n",
    "\n",
    "y_pred = [\n",
    "    [0, 1, 2],\n",
    "    [1],\n",
    "    [0, 2, 3],\n",
    "    [2, 3, 4, 0],\n",
    "    [0, 1, 2],\n",
    "    [0]\n",
    "]\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    for j in range(1, 4):\n",
    "        print(\n",
    "            f\"\"\"\n",
    "            y_true={y_true[i]},\n",
    "            y_pred={y_pred[i]},\n",
    "            AP@{j}={apk(y_true[i], y_pred[i], k=j)}\n",
    "            \"\"\"\n",
    "        )\n",
    "print(\"=========================================================================\")\n",
    "print(\"Mean Average Precision at 1: \",mapk(y_true, y_pred, 1))\n",
    "print(\"Mean Average Precision at 2: \",mapk(y_true, y_pred, 2))\n",
    "print(\"Mean Average Precision at 3: \",mapk(y_true, y_pred, 3))\n",
    "print(\"Mean Average Precision at 4: \",mapk(y_true, y_pred, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Absolute Error__:\n",
    "        \n",
    "        Absolute Error = abs(True Value - Predicted Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Mean Absolute Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute error\n",
    "    \"\"\"\n",
    "    # initializing the error to zero\n",
    "    error = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        error += np.abs(yt - yp)\n",
    "    return error / len(y_true)\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Mean Squared Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: mean squared error\n",
    "    \"\"\"\n",
    "    # initializing the error to zero\n",
    "    error = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        error += (yt - yp) ** 2\n",
    "    return error / len(y_true)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Root Mean Squared Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: root mean squared error\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def mean_squared_log_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Mean Squared Logarithmic Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: mean squared logarithmic error\n",
    "    \"\"\"\n",
    "    # initializing the error to zero\n",
    "    error = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        error += (np.log(1 + yt) - np.log(1 + yp)) ** 2\n",
    "    return error / len(y_true)\n",
    "\n",
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Root Mean Squared Logarithmic Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: root mean squared logarithmic error\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def mean_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Mean Percentage Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: mean percentage error\n",
    "    \"\"\"\n",
    "    # initializing the error to zero\n",
    "    error = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        error += (yt - yp) / yt\n",
    "    return error / len(y_true)\n",
    "\n",
    "def mean_abs_percentage_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Mean Absolute Percentage Error\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: mean absolute percentage error\n",
    "    \"\"\"\n",
    "    # initializing the error to zero\n",
    "    error = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        error += np.abs(yt - yp) / yt\n",
    "    return error / len(y_true)\n",
    "\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate R-squared Score\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real values, predicted values\n",
    "    :return: r-squared score\n",
    "    \"\"\"\n",
    "    # calculate the mean value of the true values\n",
    "    mean_true_value = np.mean(y_true)\n",
    "    \n",
    "    # initializing the numerator and denominator to zero\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    \n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        numerator += (yt - yp) ** 2\n",
    "        denominator += (yt - mean_true_value) ** 2\n",
    "    \n",
    "    ratio = numerator / denominator\n",
    "    return 1 - ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
